{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import Libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from kneed import KneeLocator\n",
    "from pyclustering.cluster.clarans import clarans\n",
    "from pyclustering.cluster.silhouette import silhouette\n",
    "from pyclustering.cluster import cluster_visualizer\n",
    "from pyclustering.cluster.kmeans import kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Prepare Dataset</h2>\n",
    "<h5>\n",
    "1. Load original dataset<br>\n",
    "2. Drop missing values<br>\n",
    "3. Delete unnecessary attribute<br>\n",
    "4. Label encoding for categorial attribute\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('./housing.csv')\n",
    "\n",
    "# Drop missing values\n",
    "df.dropna(axis = 'rows', inplace = True)\n",
    "\n",
    "# Delete unnecessary attribute\n",
    "df.drop('median_house_value', axis = 'columns', inplace = True)\n",
    "\n",
    "# Label encoding for categorial attribute\n",
    "l_er = LabelEncoder()\n",
    "df['ocean_proximity'] = l_er.fit_transform(df['ocean_proximity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Find various combinations of the features</h2>\n",
    "<h5>using Pearson Correlation of features</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find various combinations of the features using Pearson Correlation of features\n",
    "colormap = plt.cm.PuBu\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Person Correlation of Features\", y = 1.05, size = 15)\n",
    "sns.heatmap(df.astype(float).corr(), linewidths = 0.1, vmax = 1.0, square = True, cmap = colormap, linecolor = \"white\", annot = True, annot_kws = {\"size\" : 16})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kmeans_silhoutte_elbow(cluster_lists, X_features, scaler)<br>\n",
    "Parameter: cluster_lists:: List<br>\n",
    "          The number of clusters in list\n",
    "\n",
    "           X_features:: pd.Dataframe<br>\n",
    "           The dataset to perform clustering\n",
    "\n",
    "           scaler:: scalers in sklearn.preprocessing\n",
    "           The scaler to transform dataset\n",
    "<br>\n",
    "Describe: Visualize silhouette score after clustering\n",
    "          <br>And visualize elbow plot and KMeans clustering result\n",
    "\n",
    "          1. Clear the result array\n",
    "          2. KMeans clustering with defined hyperparameter\n",
    "          3. Calculate silhouette score\n",
    "          4. Visualize the result with bar graph\n",
    "          5. Repeat with given number of cluster in list\n",
    "          6. Call functions to visualize elbow plot and clustering result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_silhouette_eblow(cluster_lists, X_features, scaler):\n",
    "    # Clear the result array\n",
    "    sse.clear()\n",
    "    silhouette_avg_n_clusters.clear()\n",
    "\n",
    "    n_cols = len(cluster_lists)\n",
    "\n",
    "    # Prepare subplots\n",
    "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "    fig.subplots_adjust(top=0.8)\n",
    "\n",
    "    # Repeat with given number of cluster in list\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "\n",
    "        # Calculate silhouette score after KMeans clustering\n",
    "        clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state=0)\n",
    "        cluster_labels = clusterer.fit_predict(X_features)\n",
    "        sse.append(clusterer.inertia_)\n",
    "        print('[Running] : {:.2f}%'.format(n_cluster/len(cluster_lists)*50))\n",
    "\n",
    "        sil_avg = silhouette_score(X_features, cluster_labels)\n",
    "        sil_values = silhouette_samples(X_features, cluster_labels)\n",
    "        silhouette_avg_n_clusters.append(sil_avg)\n",
    "\n",
    "        y_lower = 10\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\\n' \\\n",
    "                          'Silhouette Score :' + str(round(sil_avg,3)) )\n",
    "        axs[ind].set_xlabel(\"The silhouette coefficient values\")\n",
    "        axs[ind].set_ylabel(\"Cluster label\")\n",
    "        axs[ind].set_xlim([-0.1, 1])\n",
    "        axs[ind].set_ylim([0, len(X_features) + (n_cluster + 1) * 10])\n",
    "        axs[ind].set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        axs[ind].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "        # Visualize using bar graph, for each cluster number\n",
    "        for i in range(n_cluster):\n",
    "            ith_cluster_sil_values = sil_values[cluster_labels==i]\n",
    "            ith_cluster_sil_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_sil_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.nipy_spectral(float(i) / n_cluster)\n",
    "            axs[ind].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \\\n",
    "                                facecolor=color, edgecolor=color, alpha=0.7)\n",
    "            axs[ind].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "            y_lower = y_upper + 10\n",
    "\n",
    "        axs[ind].axvline(x=sil_avg, color=\"red\", linestyle=\"--\")\n",
    "    plt.suptitle(scaler, fontsize=12, fontweight='bold', y=0.98)\n",
    "    plt.show()\n",
    "\n",
    "    # Call functions to draw elbow plot and Kmeans result\n",
    "    elbowPlot(scaler)\n",
    "    K_means_plot(X_features, range(2, 11, 2), scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elbowPlot(scaler):<br>\n",
    "Parameter:\n",
    "\n",
    "            scaler:: scalers in sklearn.preprocessing\n",
    "            The scaler to transform dataset\n",
    "\n",
    "\n",
    "Describe: Visualize elbow plot after clustering\n",
    "\n",
    "             1. Initialize with stored result\n",
    "             2. Visualize elbow plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbowPlot(scaler):\n",
    "    kl = KneeLocator(\n",
    "        range(2, 11, 2), sse, curve=\"convex\", direction=\"decreasing\"\n",
    "    )\n",
    "    kl.plot_knee()\n",
    "    plt.title(scaler)\n",
    "    plt.show()\n",
    "\n",
    "    print('elbow:', kl.elbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " K_means_plot(dataset, cluster_lists, scaler)<br>\n",
    "\n",
    " Parameter: dataset:: pd.Dataframe<br>\n",
    "            The dataset to perform clustering\n",
    "\n",
    "            cluster_lists:: List\n",
    "            The number of clusters in list\n",
    "\n",
    "            scaler:: scalers in sklearn.preprocessing\n",
    "            The scaler to transform dataset\n",
    "\n",
    " Describe: Visualize KMeans clustering result\n",
    "\n",
    "           1. Do PCA to plot graph\n",
    "           2. KMeans clustering with defined hyperparameter\n",
    "           3. Labeling the clusters, draw cirle at centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_means_plot(dataset, cluster_lists, scaler):\n",
    "    # PCA\n",
    "    pca = PCA(2)\n",
    "    dataset = pca.fit_transform(dataset)\n",
    "\n",
    "    n_cols = len(cluster_lists)\n",
    "\n",
    "    # Prepare subplots\n",
    "    fig, axs = plt.subplots(figsize=(4 * n_cols, 4), nrows=1, ncols=n_cols)\n",
    "    fig.subplots_adjust(top=0.8)\n",
    "\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "        model = KMeans(n_clusters = n_cluster, max_iter=500, random_state=0)\n",
    "        km_labels = model.fit_predict(dataset)\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\\n')\n",
    "\n",
    "        # Plot the input data\n",
    "        u_labels = np.unique(km_labels)\n",
    "        centroids = model.cluster_centers_\n",
    "        for i in u_labels:\n",
    "            axs[ind].scatter(dataset[km_labels == i, 0], dataset[km_labels == i, 1], label=i)\n",
    "\n",
    "        # Labeling the clusters\n",
    "        # Draw white circles at cluster centers\n",
    "        axs[ind].scatter(centroids[:, 0], centroids[:, 1], marker='o',\n",
    "                    c=\"white\", alpha=1, s=100, edgecolor='k')\n",
    "        for i, c in enumerate(centroids):\n",
    "            axs[ind].scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                        s=25, edgecolor='k')\n",
    "    plt.suptitle(scaler, fontsize=12, fontweight='bold', y=0.98)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " gmm_cluster(dataset, scaler)<br>\n",
    " \n",
    " Parameter: dataset:: pd.Dataframe<br>\n",
    "            The dataset to perform clustering\n",
    "\n",
    "            scaler:: scalers in sklearn.preprocessing\n",
    "            The scaler to transform dataset\n",
    "\n",
    " Describe: Visualize GMM clustering result<br>\n",
    "           And visualize silhouette score after clustering\n",
    "\n",
    "           1. Do PCA to plot graph\n",
    "           2. GMM clustering with defined hyperparameter\n",
    "           3. Plot the AIC score\n",
    "           4. Call function that calculate and visualize silhoutte score\n",
    "           5. Call function that visualize GMM result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_cluster(dataset, scaler):\n",
    "    # PCA\n",
    "    pca = PCA(2,whiten=True)\n",
    "    dataset = pca.fit_transform(dataset)\n",
    "\n",
    "    # Define & Fit model\n",
    "    n_components = np.arange(50, 210, 10)\n",
    "    models = [GMM(n, covariance_type='full', random_state=0) for n in n_components]\n",
    "    aics = [model.fit(dataset).aic(dataset) for model in models]\n",
    "\n",
    "    # Plot the AIC score\n",
    "    plt.plot(n_components, aics)\n",
    "    plt.ylabel('AIC')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.title('AIC for the number of GMM components')\n",
    "    plt.axhline(y=min(aics), color=\"red\", linestyle=\"--\")\n",
    "    plt.show()\n",
    "\n",
    "    # Define & Fit model\n",
    "    gmm = GMM(n_components[aics.index(min(aics))],covariance_type='full', random_state=0)\n",
    "    gmm.fit(dataset)\n",
    "    print('{} / {} Converged : {}'.format(scaler, n_components[aics.index(min(aics))], gmm.converged_))\n",
    "\n",
    "    # Calculate silhoutte score\n",
    "    gmm_silhouette(range(2,11,2), dataset, scaler)\n",
    "\n",
    "    # Plot GMM result\n",
    "    plot_gmm(gmm, dataset)\n",
    "    plt.title('{} \\ GMM Clustering with n_components :{}'.format(scaler, gmm.n_components))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " gmm_silhouette(cluster_lists, X_features, scaler)\n",
    " \n",
    " Parameter: cluster_lists:: List<br>\n",
    "            The number of clusters in list\n",
    "\n",
    "            X_features:: pd.Dataframe\n",
    "            The dataset to perform clustering\n",
    "\n",
    "            scaler:: scalers in sklearn.preprocessing\n",
    "            The scaler to transform dataset\n",
    "\n",
    " Describe: Visualize silhouette score after clustering\n",
    "\n",
    "           1. Clear the result array\n",
    "           2. GMM with defined hyperparameter\n",
    "           4. Visualize the result with bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_silhouette(cluster_lists, X_features, scaler):\n",
    "    # Clear the result array\n",
    "    sse.clear()\n",
    "    silhouette_avg_n_clusters.clear()\n",
    "\n",
    "    n_cols = len(cluster_lists)\n",
    "\n",
    "    # Prepare subplots\n",
    "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "    fig.subplots_adjust(top=0.8)\n",
    "\n",
    "    # Repeat with given number of cluster in list\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "\n",
    "        # Calculate silhouette score after GMM clustering\n",
    "        clusterer = GMM(n_components = n_cluster, max_iter=500, random_state=0)\n",
    "        cluster_labels = clusterer.fit_predict(X_features)\n",
    "\n",
    "        print('[Running] : {:.2f}%'.format(n_cluster/len(cluster_lists)*50))\n",
    "\n",
    "        sil_avg = silhouette_score(X_features, cluster_labels)\n",
    "        sil_values = silhouette_samples(X_features, cluster_labels)\n",
    "        silhouette_avg_n_clusters.append(sil_avg)\n",
    "\n",
    "        y_lower = 10\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\\n' \\\n",
    "                          'Silhouette Score :' + str(round(sil_avg,3)) )\n",
    "        axs[ind].set_xlabel(\"The silhouette coefficient values\")\n",
    "        axs[ind].set_ylabel(\"Cluster label\")\n",
    "        axs[ind].set_xlim([-0.1, 1])\n",
    "        axs[ind].set_ylim([0, len(X_features) + (n_cluster + 1) * 10])\n",
    "        axs[ind].set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        axs[ind].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "        # Visualize using bar graph, for each cluster number\n",
    "        for i in range(n_cluster):\n",
    "            ith_cluster_sil_values = sil_values[cluster_labels==i]\n",
    "            ith_cluster_sil_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_sil_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.nipy_spectral(float(i) / n_cluster)\n",
    "            axs[ind].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \\\n",
    "                                facecolor=color, edgecolor=color, alpha=0.7)\n",
    "            axs[ind].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "            y_lower = y_upper + 10\n",
    "\n",
    "        axs[ind].axvline(x=sil_avg, color=\"red\", linestyle=\"--\")\n",
    "    plt.suptitle(scaler, fontsize=12, fontweight='bold', y=0.98)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " plot_gmm(gmm, X, label, ax):\n",
    " \n",
    " Parameter:\n",
    "            GMM:: sklearn.mixture.GaussianMixture<br>\n",
    "            GMM model to visualize\n",
    "\n",
    "            X:: pd.Dataframe\n",
    "            Dataset used in GMM\n",
    "\n",
    " Describe: Visualize GMM clustering result\n",
    "\n",
    "           1. Visualize the GMM clustering result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gmm(gmm, X, label=True, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    labels = gmm.fit(X).predict(X)\n",
    "    if label:\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=labels, s=10, cmap=plt.cm.get_cmap('rainbow', 200), zorder=2)\n",
    "    else:\n",
    "        ax.scatter(X[:, 0], X[:, 1], s=40, zorder=2)\n",
    "    ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " clustering_clarans(select_df):\n",
    "\n",
    " Parameter:\n",
    "            select_df:: pd.Dataframe<br>\n",
    "            The dataset to perform clustering\n",
    "\n",
    " Describe: Visuzlize silhoutte score, distance using wce after CLARANS clustering\n",
    "\n",
    "           1. Clear the result array\n",
    "           2. CLARANS clustering with defined hyperparameter\n",
    "           3. Calculate silhouette score\n",
    "           4. Calculate elbow wce\n",
    "           5. Visualize the results\n",
    "           6. Repeat with given number of cluster in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_clarans(select_df):\n",
    "    sil_clarans = []\n",
    "    visualizer = cluster_visualizer(10, 4)\n",
    "\n",
    "    wce=[]\n",
    "\n",
    "    # Calculate elbow wce\n",
    "    def elbow_cal_wce():\n",
    "        centers=select_df[df_medoids] # center\n",
    "        instance = kmeans(select_df, centers, ccore=False) # cluster with center\n",
    "        instance.process()\n",
    "        wce.append(instance.get_total_wce())\n",
    "\n",
    "    # Calculate distance using elbow wce\n",
    "    def cal_elbows():\n",
    "        __elbows = []\n",
    "        x0, y0 = 0.0, wce[0]\n",
    "        x1, y1 = float(len(wce)), wce[-1]\n",
    "\n",
    "        for index_elbow in range(1, len(wce) - 1):\n",
    "            x, y = float(index_elbow), wce[index_elbow]\n",
    "\n",
    "            segment = abs((y0 - y1) * x + (x1 - x0) * y + (x0 * y1 - x1 * y0))\n",
    "            norm = math.sqrt((x1 - x0) ** 2 + (y1 - y0) ** 2)\n",
    "            distance = segment / norm\n",
    "\n",
    "            __elbows.append(distance)\n",
    "        return __elbows\n",
    "\n",
    "    # For given k\n",
    "    for k in range(2, 11, 2):\n",
    "        df_clarans = clarans(select_df[0:200], k, 3, 5)\n",
    "        df_clarans.process()\n",
    "        df_medoids = df_clarans.get_medoids() # center\n",
    "        df_cluster = df_clarans.get_clusters() # cluster\n",
    "        score = silhouette(select_df, df_cluster).process().get_score() # silhouette score\n",
    "        sil_clarans.append(np.nanmean(score)) # store result\n",
    "\n",
    "        elbow_cal_wce()\n",
    "\n",
    "        if len(select_df[0])!=4: # Dismiss 4-dimensional\n",
    "            visualizer.append_clusters(df_cluster, select_df,k-2) # Visualize cluster\n",
    "            visualizer.append_cluster(df_medoids, select_df,k-2, marker='x') # Visualize center\n",
    "            visualizer.set_canvas_title(text=\"Clarans Cluster : \" + str(k), canvas=k-2)\n",
    "\n",
    "    if len(select_df[0]) != 4:  # Dismiss 4-dimensional\n",
    "        visualizer.show(figure=plt.figure(figsize=(8,6)))\n",
    "\n",
    "    print(\"Clarans Silhouette Best score : \"+str(np.max(sil_clarans)))\n",
    "    print(\"Clarans Silhouette Best cluster : \" + str(np.argmax(sil_clarans)+3))\n",
    "    plt.title('Clarans Silhouette')\n",
    "    plt.plot(range(2, 11, 2), sil_clarans)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Clarans Best cluster's Elbow WCE : \" + str(wce[np.argmax(sil_clarans)]))  # Best cluster's elbow wce\n",
    "    plt.title('Clarans Elbow WCE')\n",
    "    plt.plot(range(2, 11, 2), wce)\n",
    "    plt.show()\n",
    "\n",
    "    _elbow = cal_elbows()\n",
    "    plt.title('Clarans Elbow Distance')\n",
    "    plt.plot(range(2, 7, 2), _elbow)\n",
    "    plt.show()\n",
    "    wce = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " findOptimalNClustersDB(dataset):\n",
    "\n",
    " Parameter:\n",
    "            dataset:: pd.Dataframe<br>\n",
    "            The dataset to perform clustering\n",
    "\n",
    " Describe: Visuzlize silhoutte score, result after DBSCAN\n",
    " \n",
    "           1. Clear the result array\n",
    "           2. DBSCAN with defined hyperparameter\n",
    "           3. Calculate silhouette score\n",
    "           4. Visualize the results\n",
    "           5. Repeat with given number of cluster in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOptimalNClustersDB(dataset):\n",
    "    # Number of clusters to search for and silhouette_scores list\n",
    "    range_eps = [0.01, 0.05, 0.1]\n",
    "    silhouette_avg.clear()\n",
    "\n",
    "    fig, axs = plt.subplots(figsize=(4 * 5, 4), nrows=1, ncols=len(range_eps))\n",
    "    fig.subplots_adjust(top=0.8)\n",
    "\n",
    "    # Testing n_clusters options\n",
    "    for ind, eps in enumerate(range_eps):\n",
    "        # print(j, n_clusters, k, eps)\n",
    "        db = DBSCAN(eps=eps, n_jobs=-1)\n",
    "        cluster = db.fit(dataset)\n",
    "\n",
    "        db_labels = db.fit_predict(dataset)\n",
    "        u_labels = np.unique(cluster.labels_)\n",
    "        print(db_labels)\n",
    "        sil_avg = silhouette_score(dataset, db_labels)\n",
    "        for l in u_labels:\n",
    "            axs[ind].scatter(dataset[db_labels == l, 0], dataset[db_labels == l, 1], label=l)\n",
    "\n",
    "        axs[ind].set_title('DBSCAN with eps {}\\n'\n",
    "                            'Silhouette score : {:.4f}'.format(eps, sil_avg))\n",
    "        axs[ind].legend([], [], frameon=False)\n",
    "\n",
    "        silhouette_avg.append(sil_avg)\n",
    "        print('Silhouette Coefficient: {:.4f}'.format(sil_avg))\n",
    "    plt.suptitle('{}/{}'.format(i, j), fontsize=14, fontweight='bold', y=0.98)\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(range_eps, silhouette_avg)\n",
    "    plt.title('Silhouette Score for the number of each eps')\n",
    "    plt.xlabel('eps')\n",
    "    plt.ylabel('silhouette score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get result</h2>\n",
    "<h5>Initialize lists to save result<br>\n",
    "Set feature sets<br>\n",
    "Set scaler lists<br>\n",
    "Iterate over feature sets and scalers\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to save result\n",
    "sse = []\n",
    "silhouette_avg_n_clusters = []\n",
    "silhouette_avg = []\n",
    "\n",
    "# Set feature sets\n",
    "predictor=[['total_rooms', 'total_bedrooms'],\n",
    "           ['population', 'households'],\n",
    "           ['total_rooms', 'total_bedrooms', 'households'],\n",
    "           ['total_rooms', 'total_bedrooms', 'households','population']]\n",
    "\n",
    "# Set scaler lists\n",
    "scalers = [StandardScaler(), MaxAbsScaler(), MinMaxScaler(), RobustScaler()]\n",
    "\n",
    "# Iterate over feature sets and scalers\n",
    "for i in predictor:\n",
    "    print('----------------{}------------'.format(i))\n",
    "    select_df = df[i]\n",
    "\n",
    "    for j in scalers:\n",
    "        print('----------------{}------------'.format(j))\n",
    "        select_df = j.fit_transform(select_df)\n",
    "\n",
    "        kmeans_silhouette_eblow(range(2, 11, 2), select_df, j)\n",
    "        gmm_cluster(select_df, j)\n",
    "        clustering_clarans(select_df)\n",
    "        findOptimalNClustersDB(select_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6bc0faa7f27d399619486595601873f45d019b044a59c415ecf094d9b2bb7db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
